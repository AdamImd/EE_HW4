\section{Conditioning Diffusion}
% Your next task is to explore two key conditioning mechanisms used in modern diffusion
% models: classifier guidance (CG) (Dhariwal & Nichol, 2021) and classifier-free guidance
% (CFG) (Ho & Salimans, 2021). Both techniques allow diffusion models to steer the generation
% process toward a desired class or concept, but they achieve this through fundamentally
% different principles.
% To help you get started, we have provided the skeleton code for class-conditional sampling
% (hw4 step2 main.py) along with a lightweight diffusion model and a noise-aware classifier
% codes under the folder step2 utils. We further provided pre-trained networks for each but
% you can also train them from scratch if desired.
% Your task is to complete the implementation of the two missing sampling methods. Make
% sure to check the lines with the #TODO flag inside the hw4 step2 main.py file in order to
% complete the code. Your goals for this step are as follows:



% (a) [7 pts] Implement sample cg() to perform Classifier Guidance (CG) sampling, where
% the guidance signal is obtained from the gradient of the noise-aware classifier:
% √
% ϵ̃ = ϵθ (xt , t, ∅) − ωCG · 1 − ᾱt ∇xt log pϕ (y|xt , t),
% where ωCG is the guidance scale (provided as --cg scale in the parser). Use the reverse
% update rule of the DDPM parameterization to generate class-conditioned samples for
% digits 0–9. Present the generated digits in a 10 × 10 grid (each row represents 10
% samples from a single digit), varying ωCG ∈ {0.0, 1.0, 3.0, 5.0, 10.0} to visualize the
% strength of guidance.
% (b) [7 pts] Implement sample cfg() to perform Classifier-Free Guidance (CFG) sampling.
% Use the unconditional and conditional noise predictions from the diffusion model and
% combine them according to:
% ϵ̃ = ϵθ (xt , t, ∅) + ωCFG · (ϵθ (xt , t, c) − ϵθ (xt , t, ∅)),
% where ωCFG is the guidance scale (provided as --cfg scale in the parser). Follow the
% same reverse update as in the DDPM case, and visualize the generated digits in a
% 10 × 10 grid for ωCG ∈ {0.0, 1.0, 3.0, 5.0, 10.0}.
% (c) [6 pts] Compare the outputs of CFG and CG both qualitatively and quantitatively.
% For each method, compute:
% • Classification accuracy of the generated images using the provided noise-aware
% classifier.
% • Intra-class diversity using the intraclass diversity cosine() metric (already
% implemented for you).
% Reflect on your findings. How does the guidance scale influence sample quality and
% diversity in each method? Which method do you find more stable or visually consistent
% across classes? Based on your implementations and observations, explain the funda-
% mental difference between CG and CFG. Why do you think CFG is more popular for
% text-to-image generation?

\subsection{Implementation and Results}

I implemented both methods.. The samples used guidances of $\omega \in \{0.0, 1.0, 3.0, 5.0, 10.0\}$ for 1000 sampling steps. The results for CG are shown in Figure~\ref{fig:cg_results} and for CFG in Figure~\ref{fig:cfg_results}.

The accuracies are shown belwon in Table~\ref{tab:results} along with the intra-class diversity scores.
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Scale} & \textbf{CG Acc.} & \textbf{CG Div.} & \textbf{CFG Acc.} & \textbf{CFG Div.} \\
\hline
0.0  & 0.080 & 0.605 & 0.080 & 0.605 \\
1.0  & 0.580 & 0.504 & 0.800 & 0.417 \\
3.0  & 0.880 & 0.400 & 1.000 & 0.199 \\
5.0  & 0.930 & 0.364 & 1.000 & 0.146 \\
10.0 & 0.980 & 0.331 & 1.000 & 0.109 \\
\hline
\end{tabular}
\caption{Accuracy and diversity for CG and CFG across different guidance scales.}
\label{tab:results}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.19\textwidth]{images/step2_results/mnist_cg_0.0.png}
    \includegraphics[width=0.19\textwidth]{images/step2_results/mnist_cg_1.0.png}
    \includegraphics[width=0.19\textwidth]{images/step2_results/mnist_cg_3.0.png}
    \includegraphics[width=0.19\textwidth]{images/step2_results/mnist_cg_5.0.png}
    \includegraphics[width=0.19\textwidth]{images/step2_results/mnist_cg_10.0.png}
    \caption{Classifier Guidance (CG) results. From left to right, top to bottom: $\omega_{CG} = 0.0, 1.0, 3.0, 5.0, 10.0$. Each grid shows 10 samples per digit class (rows 0-9).}
    \label{fig:cg_results}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.19\textwidth]{images/step2_results/mnist_cfg_0.0.png}
    \includegraphics[width=0.19\textwidth]{images/step2_results/mnist_cfg_1.0.png}
    \includegraphics[width=0.19\textwidth]{images/step2_results/mnist_cfg_3.0.png}
    \includegraphics[width=0.19\textwidth]{images/step2_results/mnist_cfg_5.0.png}
    \includegraphics[width=0.19\textwidth]{images/step2_results/mnist_cfg_10.0.png}
    \caption{Classifier-Free Guidance (CFG) results. From left to right, top to bottom: $\omega_{CFG} = 0.0, 1.0, 3.0, 5.0, 10.0$. Each grid shows 10 samples per digit class (rows 0-9).}
    \label{fig:cfg_results}
\end{figure}

\subsubsection{Reflections}
From the results, The CFG got higher accuracies at lower guidance scales compared to CG. However, this came at the cost of diversity, as the CFG samples had lower intra-class diversity scores, especially at higher guidance scales. 

Both models had the trend of increasing accuracy and decreasing diversity as the guidance scale increased. This makes sense beause a higher guidance makes the model move twards the class manifold, potentially reducing the entropy available for diversity. The higher the proprity of the class, the less important the original noise was influencing the sample.

CFG is the most stable, but all the digits look very similar to each other. However, if I had to choose, CG 10.0 looks the most diverse and accurate given all the configurations. 

The fundamental difference between these methods is that CG has external classification that pushes the sample twards the class, wheras the CFG uses the internal knowledge of the model to steer the sample. This is better for many modern applications as text is more diverse and does not have discrete classes, so CG would be difficult to implement. 