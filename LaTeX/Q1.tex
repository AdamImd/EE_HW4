\subsection{Posterior Samplers for Inverse Problems}
for each of the following tasks, I got results for three images from each of the two datastes, for each of the four inverse problems. I will only be including one image from each dataset for each task in the report, but the full results are included in the zip file submission. Please refer to the appendix for the images corresponding to each method and dataset. I will report the PSNR, SSIM, and LPIPS for the images shown in the report, but the full results across all three images are also included in the zip file submission.

I used my lab's server to generate the images for this task, which has an NVIDIA A6000, with 1TB ram and 128 CPU cores. 
% Step 1 (35 points): Posterior Samplers for Inverse Problems
% Your first task is to implement and compare different posterior sampling methods for solving
% inverse problems using a pre-trained ADM model1 (Dhariwal & Nichol, 2021) from HW3.
% However, unlike unconditional generation in HW3, posterior sampling aims to reconstruct an
% image that is both consistent with a given measurement (e.g., noisy masked or low resolution
% image) and plausible under the learned data prior.
% To help you get started, we have provided the skeleton code for restoration (hw4 step1 main.py)
% along with the ADM model codes and some helper functions (utils.py) under the folder
% step1 utils. Make sure to check the lines with the #TODO flag inside the hw4 step1 main.py
% file in order to complete the code. Some pointers about the model and code:
% † We have provided the CelebA-HQ and ImageNet pretrained ADM checkpoints (click).
% Please download these .pt files and place them under "./step1 utils/models/".
% 1https://github.com/openai/guided-diffusion
% 1
% † This code builds upon the unconditional generation framework from HW3 and uses the
% same ADM backbone, but trained on a different dataset. In this step, you will extend
% that framework from pure image generation to posterior sampling, where the diffusion
% model is conditioned on measurement consistency. Therefore, most of the information
% from the ADM setup in HW3 remains applicable.
% Algorithm 1 Posterior Sampling Strategies
% Require: T, y, { ˜σi}T
% i=1, η
% 1: xT ∼ N (0, I)
% 2: for t = T, ..., 1 do
% 3: ˆx0|t ← 1√ ¯αt · (xt − ˆϵθ(xt, t)√1 − ¯αt) ▷ Tweedie denoised estimate
% 4: x′
% t−1 ∼ p(xt−1|xt, ˆx0|t) ▷ DDIM sampling
% 5: xt−1 ← Projection or gradient update via x′
% t−1 and ˆx0|t to get closer to {x|y = Ax}
% 6: end for
% 7: return x0
% Figure 2: Four degradations that will be covered in this HW. You can change the box
% indices as long as you keep it 128×128 and at least 10 pixels away from the edges.
% For this step, your goals are:

\subsubsection{A: Predict $\hat{x_0}$ and sample ddim}
% (a) [4 pts] Implement predict x0 hat() and sample ddim() functions, effectively repro-
% ducing Alg. 1 excluding line 5, to ensure you can perform unconditional sampling from
% both pretrained ADM models. Use η = 1.0 throughout this assignment, thereby im-
% plementing the DDPM variant. Run the sampling process for 1000 steps and present
% five different samples from each network in a 2 × 5 grid.
% 2

I implemened the DDIM from HW3, the results are shown in Figure~\ref{fig:uncond_samples}. The images generated look qualitatively similar to those from HW3, and the model for each dataset creates images from that distrobution.

\begin{figure*}[ht]
    \centering
    % CelebA-HQ samples (top row)
    \includegraphics[width=0.18\textwidth]{images/step1_results/CelebA_HQ/unconditional/sample_1.png}\hspace{2mm}
    \includegraphics[width=0.18\textwidth]{images/step1_results/CelebA_HQ/unconditional/sample_2.png}\hspace{2mm}
    \includegraphics[width=0.18\textwidth]{images/step1_results/CelebA_HQ/unconditional/sample_3.png}\hspace{2mm}
    \includegraphics[width=0.18\textwidth]{images/step1_results/CelebA_HQ/unconditional/sample_4.png}\hspace{2mm}
    \includegraphics[width=0.18\textwidth]{images/step1_results/CelebA_HQ/unconditional/sample_5.png}
    \\[2mm]
    % ImageNet samples (bottom row)
    \includegraphics[width=0.18\textwidth]{images/step1_results/ImageNet/unconditional/sample_1.png}\hspace{2mm}
    \includegraphics[width=0.18\textwidth]{images/step1_results/ImageNet/unconditional/sample_2.png}\hspace{2mm}
    \includegraphics[width=0.18\textwidth]{images/step1_results/ImageNet/unconditional/sample_3.png}\hspace{2mm}
    \includegraphics[width=0.18\textwidth]{images/step1_results/ImageNet/unconditional/sample_4.png}\hspace{2mm}
    \includegraphics[width=0.18\textwidth]{images/step1_results/ImageNet/unconditional/sample_5.png}
    \caption{Unconditional samples from CelebA-HQ (top row) and ImageNet (bottom row) pretrained ADM models using DDIM sampling with 1000 steps.}
    \label{fig:uncond_samples}
\end{figure*}




\subsubsection{B: Implement and compare posterior samplers}
% (b) [8 pts] As discussed in the class, earlier attempts focused on direct projections onto
% the constraint set. For example, Iterative Latent Variable Refinement (ILVR) (Choi
% et al., 2021) which is initially proposed for super-resolution (SR) tasks considers the
% following update for line 5 (Alg. 1):
% xt−1 = x′
% t−1 + ζILVR · A†(yt−1 − Ax′
% t−1),
% where ζILVR is the weighting parameter, A† is the left-pseudoinverse of the forward
% operator, and yt−1 ∼ q(yt−1|y0).
% • Select 3 images from each dataset’s validation set provided to you (click) and
% place them in their corresponding folders under "./step1 utils/data/". Note:
% Their pre-trained networks are different so do not forget to change the --dataset
% parser for the correct network prior. Also do not forget to have some fun so choose
% the celebrities you know! Let’s see if you can recognize them after reconstruction!
% • Implement the q sample() function to perform the forward noising process de-
% fined as q(xt−1 | x0) = N (xt−1; √¯αt−1 x0, (1 − ¯αt−1)I).
% • Implement the ilvr() function to perform ILVR’s ∇xt p(y|x) update. Use the
% implemented q sample() function to obtain the noisy measurements yt−1.
% • Perform image restoration for the following inverse problem tasks: (i) SR×4, (ii)
% SR×8, (iii) 80% random inpainting, and (iv) 128×128 box inpainting. Assume
% σy = 0 and use 1000 sampling steps. Tune ζILVR heuristically for best per-
% formance, and report reference, measurement, and reconstruction for each image
% along with their corresponding PSNR, SSIM, and LPIPS metrics. Note:
% These degradations are already defined for you. You only need to change them
% from parser operations.
% • Discuss the observed performance and report the restoration time per image.
% Do you obtain similar results for inpainting tasks as for super-resolution tasks? If
% not, why might that be the case?

I found that an ILVR weight of 0.8 worked well during initial tests, so I used that value for all tasks. For this task I inlcuded the results from CelebA-HQ and ImageNet datasets in Figures~\ref{fig:ilvr_celeba} and \ref{fig:ilvr_imagenet}. 

The CelebA model had an average performance of:
\begin{list}{-}{ }
    \item Time: 50s
    \item SRx4:
    \subitem PSNR: 30.97
    \subitem SSIM: 0.880
    \subitem LPIPS: 0.0729
    \item SRx8:
    \subitem PSNR: 26.44
    \subitem SSIM: 0.7464
    \subitem LPIPS: 0.1243
    \item 80\% random inpainting:
    \subitem PSNR: 20.86
    \subitem SSIM: 0.5541
    \subitem LPIPS: 0.4891
    \item 128x128 box inpainting:
    \subitem PSNR: 20.33
    \subitem SSIM: 0.8244
    \subitem LPIPS: 0.1231
\end{list}

The ImageNet model had an average performance of:
\begin{list}{-}{ }
    \item Time: 176s
    \item SRx4:
        \subitem PSNR: 25.33
        \subitem SSIM: 0.735
        \subitem LPIPS: 0.2653
    \item SRx8:
        \subitem PSNR: 22.10
        \subitem SSIM: 0.5647
        \subitem LPIPS: 0.2642
    \item 80\% random inpainting:
        \subitem PSNR: 15.95
        \subitem SSIM: 0.1889
        \subitem LPIPS: 0.9146
    \item 128x128 box inpainting:
        \subitem PSNR: 17.23
        \subitem SSIM: 0.7826
        \subitem LPIPS: 0.2218
\end{list}


\subsubsection{C: Manifold Constrained Gradient (MCG)}  
% (c) [6 pts] Manifold Constrained Gradient (MCG) (Chung et al., 2022) improves upon
% ILVR by first taking a gradient step along the manifold followed by a projection step
% similar to ILVR (but with A⊤ instead of A†):
% ˜xt−1 = x′
% t−1 − ζMCG · ∇xt ||y − Aˆx0|t||2
% xt−1 = x′
% t−1 + A⊤(yt−1 − A˜xt−1)
% • Implement the mcg() function and perform image restoration for the following
% inverse problem tasks: (i) SR×4, (ii) SR×8, (iii) 80% random inpainting, and
% (iv) 128×128 box inpainting. Assume σy = 0 and use 1000 sampling steps.
% Tune ζMCG heuristically for best performance, and report reference, measurement,
% and reconstruction for each image along with their corresponding PSNR, SSIM,
% and LPIPS metrics. Note: Use the same 3 images from part (b) and obtain
% yt−1 similar to ILVR using q sample() function.
% 3
% • Discuss the observed performance and report the restoration time per image.
% Compare the speed and quality to ILVR. Do you see consistent performance across
% restoration tasks this time? Although MCG also requires 1000 sampling (denois-
% ing) steps, do you notice any slowness compared to ILVR? Discuss.

MCG produced 

\begin{list}{-}{ }
    \item Time: 55s
    \item SRx4:
        \subitem PSNR: 19.68
        \subitem SSIM: 0.8047
        \subitem LPIPS: 0.1846
    \item SRx8:
        \subitem PSNR: 25.68
        \subitem SSIM: 0.7404
        \subitem LPIPS: 0.1335
    \item 80\% random inpainting:
        \subitem PSNR: 33.40
        \subitem SSIM: 0.9260
        \subitem LPIPS: 0.0359
    \item 128x128 box inpainting:
        \subitem PSNR: 19.68
        \subitem SSIM:0.8047
        \subitem LPIPS: 0.1856
\end{list}



\begin{list}{-}{ }
    \item Time: 178s
    \item SRx4:
        \subitem PSNR: 12.75
        \subitem SSIM: 0.3567
        \subitem LPIPS: 0.6224
    \item SRx8:
        \subitem PSNR: 14.46
        \subitem SSIM: 0.3693
        \subitem LPIPS: 0.4716
    \item 80\% random inpainting:
        \subitem PSNR: 23.98
        \subitem SSIM: 0.7838
        \subitem LPIPS: 0.2242
    \item 128x128 box inpainting:
        \subitem PSNR: 14.11
        \subitem SSIM: 0.7472
        \subitem LPIPS: 0.3034
\end{list}




\subsubsection{D: Denoising Diffusion Null-Space Model (DDNM)}
% (d) [6 pts] Denoising Diffusion Null-Space Model (DDNM) (Wang et al., 2023) replaces
% the line 5 update in Alg. 1 with an update from a range-null-space decomposition of
% the forward operator. Specifically, at each step, it forms the Tweedie estimate ˆx0|t and
% projects it onto the affine constraint set as:
% ˜x0|t = ˆx0|t + ζDDNM · A†(y − Aˆx0|t).
% The goal here is to enforce exact data consistency in the range of A, while preserving
% the null-space component favored by the prior. Once this refined denoised estimate
% is obtained, DDNM gets the final sample as x′
% t−1 ∼ p(xt−1|xt, ˜x0|t). Given this new
% formulation, DDNM improves upon past methods in terms of required sampling steps.
% • Implement the ddnm() function and perform image restoration for the following
% inverse problem tasks: (i) SR×4, (ii) SR×8, (iii) 80% random inpainting, and (iv)
% 128×128 box inpainting. Assume σy = 0 and use 100 sampling steps. Tune
% ζDDNM heuristically for best performance, and report reference, measurement, and
% reconstruction for each image along with their corresponding PSNR, SSIM, and
% LPIPS metrics. Note: Use the same 3 images from part (b).
% • Discuss the observed performance and report the restoration time per image.
% Compare the speed and quality to ILVR and MCG.

\begin{list}{-}{ }
    \item Time: 3s
    \item SRx4:
        \subitem PSNR: 18.25
        \subitem SSIM: 0.2746
        \subitem LPIPS: 0.8742
    \item SRx8:
        \subitem PSNR: 17.02
        \subitem SSIM: 0.2033
        \subitem LPIPS: 1.0188
    \item 80\% random inpainting:
        \subitem PSNR: 10.87
        \subitem SSIM: 0.0629
        \subitem LPIPS: 14.827
    \item 128x128 box inpainting:
        \subitem PSNR: 15.83
        \subitem SSIM: 0.7219
        \subitem LPIPS: 0.5116
\end{list}

\begin{list}{-}{ }
    \item Time: 9s
    \item SRx4:
        \subitem PSNR: 13.33
        \subitem SSIM: 0.3296
        \subitem LPIPS: 0.8221
    \item SRx8:
        \subitem PSNR: 12.76
        \subitem SSIM: 0.2855
        \subitem LPIPS: 0.9485
    \item 80\% random inpainting:
        \subitem PSNR: 8.03
        \subitem SSIM: 0.0324
        \subitem LPIPS: 1.4114
    \item 128x128 box inpainting:
        \subitem PSNR: 13.24
        \subitem SSIM: 0.7202
        \subitem LPIPS: 0.5390
\end{list}

\subsubsection{E: Noisy measurements and Diffusion Posterior Sampling (DPS)}
% (e) [5 pts] Add noise to the measurements with σy = 0.05 (use --sigma y). Repeat steps
% (b), (c), and (d) only for the SR×4 and box inpainting tasks on a single dataset (either
% CelebA-HQ or ImageNet). Report reference, measurement, and reconstruction for each
% image. Do you observe any performance degradation for ILVR, MCG, or DDNM? Is
% the drop in performance more pronounced for one inverse task compared to the other
% (SR×4 vs box inpainting)? Explain your reasoning for each case.

% \begin{figure}
%     \centering
%     \includegraphics[width=0.9\columnwidth]{images/step1_results/CelebA_HQ_1E/Noisy_ILVR/SR_x4/recon_3.png}
%     \includegraphics[width=0.9\columnwidth]{images/step1_results/CelebA_HQ/Noisy_ILVR/Inpainting_box/recon_3.png}
%     \caption{ILVR Reconstructions on CelebA-HQ with noisy measurements for SRx4 and 128x128 box inpainting.}
%     \label{fig:noisy_ilvr_celeba}
% \end{figure}


\begin{list}{-}{ }
    \item Time:
    \item SRx4:
        \subitem PSNR:
        \subitem SSIM:
        \subitem LPIPS:
    \item SRx8:
        \subitem PSNR:
        \subitem SSIM:
        \subitem LPIPS:
    \item 80\% random inpainting:
        \subitem PSNR:
        \subitem SSIM:
        \subitem LPIPS:
    \item 128x128 box inpainting:
        \subitem PSNR:
        \subitem SSIM:
        \subitem LPIPS:
\end{list}


\begin{list}{-}{ }
    \item Time:
    \item SRx4:
        \subitem PSNR:
        \subitem SSIM:
        \subitem LPIPS:
    \item SRx8:
        \subitem PSNR:
        \subitem SSIM:
        \subitem LPIPS:
    \item 80\% random inpainting:
        \subitem PSNR:
        \subitem SSIM:
        \subitem LPIPS:
    \item 128x128 box inpainting:
        \subitem PSNR:
        \subitem SSIM:
        \subitem LPIPS:
\end{list}


\subsubsection{F: Diffusion Posterior Sampling (DPS) for noisy measurements}
% (f) [6 pts] Diffusion Posterior Sampling (DPS) (Chung et al., 2023) applies MCG up-
% date for the most part but it removes the final projection step for stability to noisy
% conditions. Therefore, its update is given as:
% xt−1 = x′
% t−1 − ζDPS · ∇xt ||y − Aˆx0|t||2
% • Implement the dps() function and perform image restoration for the following
% inverse problem tasks: (i) SR×4, (ii) SR×8, (iii) 80% random inpainting, and
% (iv) 128×128 box inpainting. Assume σy = 0.05 and use 1000 sampling steps.
% Tune ζDPS heuristically for best performance, and report reference, measurement,
% and reconstruction for each image along with their corresponding PSNR, SSIM,
% and LPIPS metrics. Note: Use the same 3 images from part (b).
% • Discuss the observed performance and report the restoration time per image.
% Compare the speed and quality to ILVR, MCG and DDNM. Do you see improved
% performance across noisy conditions? Discuss


\begin{list}{-}{ }
    \item Time: 55s
    \item SRx4:
        \subitem PSNR: 22.94
        \subitem SSIM: 0.7031
        \subitem LPIPS: 0.2730
    \item SRx8:
        \subitem PSNR: 26.43
        \subitem SSIM: 0.7592
        \subitem LPIPS: 0.1143
    \item 80\% random inpainting:
        \subitem PSNR: 19.02
        \subitem SSIM: 0.7389
        \subitem LPIPS: 0.3173
    \item 128x128 box inpainting:
        \subitem PSNR: 11.92
        \subitem SSIM: 0.3863
        \subitem LPIPS: 0.5397
\end{list}


\begin{list}{-}{ }
    \item Time: 177s
    \item SRx4:
        \subitem PSNR: 13.22
        \subitem SSIM: 0.3813
        \subitem LPIPS: 0.4515
    \item SRx8:
        \subitem PSNR: 16.65
        \subitem SSIM: 0.4041
        \subitem LPIPS: 0.3862
    \item 80\% random inpainting:
        \subitem PSNR: 19.34
        \subitem SSIM: 0.5619
        \subitem LPIPS: 0.4727
    \item 128x128 box inpainting:
        \subitem PSNR: 13.69
        \subitem SSIM: 0.5530
        \subitem LPIPS: 0.4243
\end{list}